{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marwanelhanafey/Tensorflow-and-PyTorch/blob/main/Tensorflow%20and%20PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2r_M09geMJ6"
      },
      "source": [
        "# Tensorflow_Pytorch_Lab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoAVDbheeMKN"
      },
      "source": [
        "## Nessesary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P1bZudGmeMKO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qfd0k2D8fj3N",
        "outputId": "0c19c533-d00b-45f3-97c0-c8ce93ab0d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: unknown command \"onnx\"\n"
          ]
        }
      ],
      "source": [
        "pip onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf01eV-IxrlL"
      },
      "source": [
        "## Tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lm8MhhzGw90G"
      },
      "outputs": [],
      "source": [
        "def run_tensorflow():\n",
        "    # Load and preprocess MNIST data\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    x_train, x_test = x_train.reshape(-1, 784) / 255.0, x_test.reshape(-1, 784) / 255.0\n",
        "\n",
        "    # Build model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train model, capture history to get loss\n",
        "    start_train = time.time()\n",
        "    history = model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=2)\n",
        "    train_time = time.time() - start_train\n",
        "    print(f\"Training time (TF): {train_time:.2f} s\")\n",
        "\n",
        "    # Get final training loss from last epoch\n",
        "    final_loss = history.history['loss'][-1]\n",
        "\n",
        "    # Evaluate model\n",
        "    start_eval = time.time()\n",
        "    loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    infer_time = time.time() - start_eval\n",
        "    print(f\"Test Accuracy (TF): {acc:.4f}\")\n",
        "    print(f\"Inference time (TF): {infer_time:.2f} s\")\n",
        "\n",
        "    # Export to TFLite\n",
        "    tflite_model = tf.lite.TFLiteConverter.from_keras_model(model).convert()\n",
        "    tflite_path = \"model.tflite\"\n",
        "    with open(tflite_path, \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    # Get model size in MB\n",
        "    model_size_mb = os.path.getsize(tflite_path) / (1024 * 1024)\n",
        "\n",
        "    return train_time, infer_time, acc, model_size_mb, final_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0POymqklxR87"
      },
      "source": [
        "## MNIST Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5ha2ZaBjeMKT"
      },
      "outputs": [],
      "source": [
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(784, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1iDaBqgeMKT"
      },
      "source": [
        "## Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ov-bHSkuxRLe"
      },
      "outputs": [],
      "source": [
        "def run_pytorch():\n",
        "    # Data loading and normalization\n",
        "    transform = transforms.Compose([transforms.ToTensor()])\n",
        "    train_data = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "    test_data = datasets.MNIST(root='.', train=False, transform=transform)\n",
        "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_data, batch_size=1000)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = MNISTModel().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    model.train()\n",
        "    start_train = time.time()\n",
        "    final_loss = None\n",
        "    for epoch in range(5):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        final_loss = running_loss / len(train_loader)  # Average loss per batch for the last epoch\n",
        "    train_time = time.time() - start_train\n",
        "    print(f\"Training time (PyTorch): {train_time:.2f} s\")\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_eval = time.time()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    infer_time = time.time() - start_eval\n",
        "    accuracy = correct / total\n",
        "    print(f\"Test Accuracy (PyTorch): {accuracy:.4f}\")\n",
        "    print(f\"Inference time (PyTorch): {infer_time:.2f} s\")\n",
        "\n",
        "    dummy_input = torch.randn(1, 784, device=device)\n",
        "    onnx_path = \"model.onnx\"\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        dummy_input,\n",
        "        onnx_path,\n",
        "        input_names=[\"input\"],\n",
        "        output_names=[\"output\"],\n",
        "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
        "    )\n",
        "    model_size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
        "\n",
        "    return train_time, infer_time, accuracy, model_size_mb, final_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wDiC0ECeMKV"
      },
      "source": [
        "## Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9P9vZq1MeMKW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_comprehensive(frameworks, training_time, inference_time, accuracy, loss, output_img='comparison_full_metrics.png'):\n",
        "    x = np.arange(len(frameworks))\n",
        "    width = 0.4\n",
        "\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    # Training Time\n",
        "    axs[0, 0].bar(x, training_time, width, color='skyblue')\n",
        "    axs[0, 0].set_title('Training Time (s)')\n",
        "    axs[0, 0].set_xticks(x)\n",
        "    axs[0, 0].set_xticklabels(frameworks)\n",
        "    for i, v in enumerate(training_time):\n",
        "        axs[0, 0].text(i, v + 0.1, f\"{v:.2f}\", ha='center')\n",
        "\n",
        "    # Inference Time\n",
        "    axs[0, 1].bar(x, inference_time, width, color='lightgreen')\n",
        "    axs[0, 1].set_title('Inference Time (s)')\n",
        "    axs[0, 1].set_xticks(x)\n",
        "    axs[0, 1].set_xticklabels(frameworks)\n",
        "    for i, v in enumerate(inference_time):\n",
        "        axs[0, 1].text(i, v + 0.01, f\"{v:.3f}\", ha='center')\n",
        "\n",
        "    # Accuracy\n",
        "    axs[1, 0].bar(x, accuracy, width, color='gold')\n",
        "    axs[1, 0].set_title('Test Accuracy')\n",
        "    axs[1, 0].set_ylim(0, 1)\n",
        "    axs[1, 0].set_xticks(x)\n",
        "    axs[1, 0].set_xticklabels(frameworks)\n",
        "    for i, v in enumerate(accuracy):\n",
        "        axs[1, 0].text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n",
        "\n",
        "    # Loss\n",
        "    axs[1, 1].bar(x, loss, width, color='salmon')\n",
        "    axs[1, 1].set_title('Final Training Loss')\n",
        "    axs[1, 1].set_xticks(x)\n",
        "    axs[1, 1].set_xticklabels(frameworks)\n",
        "    for i, v in enumerate(loss):\n",
        "        axs[1, 1].text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(output_img, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Full comparison metrics saved to {output_img}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJj4WUuOeMKX"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrPDjaRZgFTn",
        "outputId": "3d81037d-3217-4cf2-a547-6f83d5e489c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.14.0)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/17.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/17.6 MB\u001b[0m \u001b[31m206.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m14.3/17.6 MB\u001b[0m \u001b[31m212.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m234.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw0lbNDuWete",
        "outputId": "167ed0e6-fb8b-4c69-ffa9-0eb4f0682e39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running TensorFlow MNIST model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 - 9s - 5ms/step - accuracy: 0.9161 - loss: 0.3031\n",
            "Epoch 2/5\n",
            "1875/1875 - 7s - 4ms/step - accuracy: 0.9568 - loss: 0.1465\n",
            "Epoch 3/5\n",
            "1875/1875 - 5s - 3ms/step - accuracy: 0.9684 - loss: 0.1067\n",
            "Epoch 4/5\n",
            "1875/1875 - 4s - 2ms/step - accuracy: 0.9744 - loss: 0.0843\n",
            "Epoch 5/5\n",
            "1875/1875 - 6s - 3ms/step - accuracy: 0.9798 - loss: 0.0675\n",
            "Training time (TF): 32.31 s\n",
            "Test Accuracy (TF): 0.9724\n",
            "Inference time (TF): 1.48 s\n",
            "Saved artifact at '/tmp/tmph9jyyfrn'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 784), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138055391123152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138055391126608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138055391128528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138055391122768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\n",
            "Running PyTorch MNIST model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.60MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.25MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.78MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time (PyTorch): 45.60 s\n",
            "Test Accuracy (PyTorch): 0.9721\n",
            "Inference time (PyTorch): 1.02 s\n",
            "Full comparison metrics saved to comparison_full_metrics.png\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"Running TensorFlow MNIST model...\")\n",
        "    tf_train_time, tf_infer_time, tf_acc, tf_model_size, tf_loss = run_tensorflow()\n",
        "\n",
        "    print(\"\\nRunning PyTorch MNIST model...\")\n",
        "    pt_train_time, pt_infer_time, pt_acc, pt_model_size, pt_loss = run_pytorch()\n",
        "\n",
        "    frameworks = ['TensorFlow', 'PyTorch']\n",
        "    training_time = [tf_train_time, pt_train_time]\n",
        "    inference_time = [tf_infer_time, pt_infer_time]\n",
        "    accuracy = [tf_acc, pt_acc]\n",
        "    loss = [tf_loss, pt_loss]\n",
        "\n",
        "    plot_comprehensive(frameworks, training_time, inference_time, accuracy, loss)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}